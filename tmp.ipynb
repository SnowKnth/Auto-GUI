{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available GPUs: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:2', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:3', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:4', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:5', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:6', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:7', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1,2,3,4,5,6,7\"\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "print(\"Available GPUs:\", gpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-29 15:43:54.146966: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-07-29 15:43:54.169917: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-07-29 15:43:54.176952: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-07-29 15:43:54.195712: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-29 15:43:55.260484: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR:tensorflow:Tensorflow needs to be built with TensorRT support enabled to allow TF-TRT to operate.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-29 15:43:56.813654: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2343] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2024-07-29 15:43:56.854187: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Tensorflow has not been built with TensorRT support.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 12\u001b[0m\n\u001b[1;32m      5\u001b[0m model \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mSequential([\n\u001b[1;32m      6\u001b[0m     tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mInput(shape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m784\u001b[39m,)),\n\u001b[1;32m      7\u001b[0m     tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mDense(\u001b[38;5;241m128\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[1;32m      8\u001b[0m     tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mDense(\u001b[38;5;241m10\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msoftmax\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      9\u001b[0m ])\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# 转换为 TensorRT 模型\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m converter \u001b[38;5;241m=\u001b[39m \u001b[43mtrt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTrtGraphConverterV2\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_saved_model_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpath_to_saved_model\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m converter\u001b[38;5;241m.\u001b[39mconvert()\n\u001b[1;32m     14\u001b[0m converter\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpath_to_saved_model_trt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/data/wxd/miniconda3/envs/Auto-UI/lib/python3.12/site-packages/tensorflow/python/util/deprecation.py:588\u001b[0m, in \u001b[0;36mdeprecated_args.<locals>.deprecated_wrapper.<locals>.new_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    580\u001b[0m         _PRINTED_WARNING[(func, arg_name)] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    581\u001b[0m       _log_deprecation(\n\u001b[1;32m    582\u001b[0m           \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFrom \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m: calling \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m (from \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m) with \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m is deprecated and will \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    583\u001b[0m           \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbe removed \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mInstructions for updating:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    586\u001b[0m           \u001b[38;5;124m'\u001b[39m\u001b[38;5;124min a future version\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m date \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m date),\n\u001b[1;32m    587\u001b[0m           instructions)\n\u001b[0;32m--> 588\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/data/wxd/miniconda3/envs/Auto-UI/lib/python3.12/site-packages/tensorflow/python/compiler/tensorrt/trt_convert.py:1261\u001b[0m, in \u001b[0;36mTrtGraphConverterV2.__init__\u001b[0;34m(self, input_saved_model_dir, input_saved_model_tags, input_saved_model_signature_key, use_dynamic_shape, dynamic_shape_profile_strategy, max_workspace_size_bytes, precision_mode, minimum_segment_size, maximum_cached_engines, use_calibration, allow_build_at_runtime, conversion_params)\u001b[0m\n\u001b[1;32m   1252\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m conversion_params \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1253\u001b[0m   conversion_params \u001b[38;5;241m=\u001b[39m TrtConversionParams(\n\u001b[1;32m   1254\u001b[0m       max_workspace_size_bytes\u001b[38;5;241m=\u001b[39mmax_workspace_size_bytes,\n\u001b[1;32m   1255\u001b[0m       precision_mode\u001b[38;5;241m=\u001b[39mprecision_mode,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1258\u001b[0m       use_calibration\u001b[38;5;241m=\u001b[39muse_calibration,\n\u001b[1;32m   1259\u001b[0m       allow_build_at_runtime\u001b[38;5;241m=\u001b[39mallow_build_at_runtime)\n\u001b[0;32m-> 1261\u001b[0m \u001b[43m_check_trt_version_compatibility\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1262\u001b[0m _check_conversion_params(conversion_params, is_v2\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   1264\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_conversion_params \u001b[38;5;241m=\u001b[39m conversion_params\n",
      "File \u001b[0;32m/data/wxd/miniconda3/envs/Auto-UI/lib/python3.12/site-packages/tensorflow/python/compiler/tensorrt/trt_convert.py:224\u001b[0m, in \u001b[0;36m_check_trt_version_compatibility\u001b[0;34m()\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _pywrap_py_utils\u001b[38;5;241m.\u001b[39mis_tensorrt_enabled():\n\u001b[1;32m    220\u001b[0m   logging\u001b[38;5;241m.\u001b[39merror(\n\u001b[1;32m    221\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTensorflow needs to be built with TensorRT support enabled to allow \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    222\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTF-TRT to operate.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 224\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTensorflow has not been built with TensorRT support.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    226\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m platform\u001b[38;5;241m.\u001b[39msystem() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWindows\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    227\u001b[0m   logging\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    228\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWindows support is provided experimentally. No guarantee is made \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    229\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mregarding functionality or engineering support. Use at your own risk.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Tensorflow has not been built with TensorRT support."
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.compiler.tensorrt import trt_convert as trt\n",
    "\n",
    "# 创建一个简单的模型\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(784,)),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# 转换为 TensorRT 模型\n",
    "converter = trt.TrtGraphConverterV2(input_saved_model_dir='path_to_saved_model')\n",
    "converter.convert()\n",
    "converter.save('path_to_saved_model_trt')\n",
    "\n",
    "# 加载 TensorRT 模型\n",
    "loaded_model = tf.saved_model.load('path_to_saved_model_trt')\n",
    "\n",
    "# 进行推理\n",
    "input_data = tf.random.uniform(shape=(1, 784))\n",
    "predictions = loaded_model(input_data)\n",
    "print(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorted Positions:\n",
      " [[ 10  30 150 250]\n",
      " [ 50  20 100 200]\n",
      " [ 70  25 120 220]]\n",
      "Sorted UI Text:\n",
      " ['Text B', 'Text A', 'Text C']\n",
      "Sorted UI Type:\n",
      " ['Type B', 'Type A', 'Type C']\n"
     ]
    }
   ],
   "source": [
    "import jax.numpy as jnp\n",
    "\n",
    "def sort_by_up_corner(positions, ui_text, ui_type):\n",
    "    # Extract the up_corner_pos from positions\n",
    "    up_corner_pos = positions[:, 0]  # Assuming up_corner_pos is the first element in each bounding box\n",
    "    \n",
    "    # Get the sorted indices based on up_corner_pos\n",
    "    sorted_indices = jnp.argsort(up_corner_pos)\n",
    "    \n",
    "    # Sort positions, ui_text, and ui_type based on sorted_indices\n",
    "    sorted_positions = positions[sorted_indices]\n",
    "    sorted_ui_text = [ui_text[i] for i in sorted_indices]\n",
    "    sorted_ui_type = [ui_type[i] for i in sorted_indices]\n",
    "    \n",
    "    return sorted_positions, sorted_ui_text, sorted_ui_type\n",
    "\n",
    "# Example usage\n",
    "positions = jnp.array([\n",
    "    [50, 20, 100, 200],\n",
    "    [10, 30, 150, 250],\n",
    "    [70, 25, 120, 220]\n",
    "])\n",
    "\n",
    "ex = {\n",
    "    'ui_text': ['Text A', 'Text B', 'Text C'],\n",
    "    'ui_type': ['Type A', 'Type B', 'Type C']\n",
    "}\n",
    "\n",
    "sorted_positions, sorted_ui_text, sorted_ui_type = sort_by_up_corner(positions, ex['ui_text'], ex['ui_type'])\n",
    "\n",
    "print(\"Sorted Positions:\\n\", sorted_positions)\n",
    "print(\"Sorted UI Text:\\n\", sorted_ui_text)\n",
    "print(\"Sorted UI Type:\\n\", sorted_ui_type)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "函数内部的局部变量total= 30\n",
      "函数内部的局部变量total的内存地址是： 9772744\n",
      "函数外部的全局变量total= 0\n",
      "函数外部的全局变量toal的内存地址是： 9771784\n"
     ]
    }
   ],
   "source": [
    "total = 0  # total是一个全局变量\n",
    "\n",
    "def plus(arg1, arg2):\n",
    "    total = arg1 + arg2  # total在这里是局部变量\n",
    "    print(\"函数内部的局部变量total=\", total)\n",
    "    print(\"函数内部的局部变量total的内存地址是：\", id(total))\n",
    "    return total\n",
    "\n",
    "plus(10, 20)\n",
    "print(\"函数外部的全局变量total=\",total)\n",
    "print(\"函数外部的全局变量toal的内存地址是：\", id(total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "2\n",
      "3\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "a = 1 # 全局变量\n",
    "def func():\n",
    "    b = 2  # 局部变量\n",
    "    print(a)   # 可以访问全局变量，无法访问它的内部c\n",
    "\n",
    "    def inner():\n",
    "        c = 3   # 更局部变量\n",
    "        print(a)  # 可以访问全局变量\n",
    "        print(b)  # b对inner函数来说就是外部变量\n",
    "        print(c)\n",
    "    inner()\n",
    "func()\n",
    "\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "函数内部的局部变量total= 30\n",
      "函数内部的局部变量total的内存地址是： 9772744\n",
      "函数外部的全局变量total= 30\n",
      "函数外部的全局变量toal的内存地址是： 9772744\n"
     ]
    }
   ],
   "source": [
    "total = 0      # total是一个全局变量\n",
    "\n",
    "def plus(arg1, arg2):\n",
    "    global total    # 使用global关键字申明此处的total引用外部的total\n",
    "    total = arg1 + arg2  # total在这里是局部变量\n",
    "    print(\"函数内部的局部变量total=\", total)\n",
    "    print(\"函数内部的局部变量total的内存地址是：\", id(total))\n",
    "    return total\n",
    "\n",
    "plus(10, 20)\n",
    "print(\"函数外部的全局变量total=\",total)\n",
    "print(\"函数外部的全局变量toal的内存地址是：\", id(total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "函数outer调用之前全局变量a的内存地址：  9771816\n",
      "函数outer调用之时闭包外部的变量a的内存地址：  9771848\n",
      "函数inner调用之后闭包内部变量a的内存地址：  9771880\n",
      "函数inner调用之后，闭包外部的变量a的内存地址：  9771848\n",
      "函数outer执行完毕，全局变量a的内存地址：  9771816\n"
     ]
    }
   ],
   "source": [
    "a = 1    # 全局变量\n",
    "print(\"函数outer调用之前全局变量a的内存地址： \", id(a))\n",
    "\n",
    "def outer():\n",
    "    a = 2   # 闭包外部的变量a\n",
    "    print(\"函数outer调用之时闭包外部的变量a的内存地址： \", id(a))\n",
    "    def inner():\n",
    "        a = 3   # 闭包内部的变量a\n",
    "        print(\"函数inner调用之后闭包内部变量a的内存地址： \", id(a))\n",
    "    inner()\n",
    "    print(\"函数inner调用之后，闭包外部的变量a的内存地址： \", id(a))\n",
    "outer()\n",
    "print(\"函数outer执行完毕，全局变量a的内存地址： \", id(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 读取Sheet1和Sheet2\n",
    "sheet1 = pd.read_excel('Name.xlsx', sheet_name='Sheet1')\n",
    "sheet2 = pd.read_excel('Name.xlsx', sheet_name='Sheet2')\n",
    "\n",
    "# 处理Sheet2的A列，分离姓名和学号\n",
    "def parse_A_col(a):\n",
    "    parts = a.split()\n",
    "    if len(parts) >= 2 and parts[-1].isdigit():\n",
    "        return {'姓名': ' '.join(parts[:-1]), '学号': parts[-1]}\n",
    "    else:\n",
    "        # 假设只有学号\n",
    "        return {'姓名': sheet1.loc[sheet1['学号'] == a, '姓名'].values[0], '学号': a}\n",
    "\n",
    "sheet2['姓名'] = sheet2['A'].apply(lambda x: parse_A_col(x)['姓名'])\n",
    "sheet2['学号'] = sheet2['A'].apply(lambda x: parse_A_col(x)['学号'])\n",
    "sheet2 = sheet2.drop(columns=['A'])\n",
    "\n",
    "# 统计每个海报的被评次数和平均分\n",
    "poster_stats = sheet2.groupby('被评海报编号')['打分'].agg(['count', 'mean']).reset_index()\n",
    "\n",
    "# 统计每个人评价的海报数量\n",
    "evaluator_counts = sheet2.groupby(['姓名', '学号'])['被评海报编号'].count().reset_index(name='评价他人海报总次数')\n",
    "\n",
    "# 合并Sheet1和poster_stats\n",
    "result = sheet1[['A', '学号', '姓名']].rename(columns={'A': '海报序号'})\n",
    "result = result.merge(poster_stats, left_on='海报序号', right_on='被评海报编号', how='left')\n",
    "result = result.drop(columns=['被评海报编号'])\n",
    "result = result.rename(columns={'count': '被评总次数', 'mean': '被评平均分'})\n",
    "\n",
    "# 合并评价次数\n",
    "result = result.merge(evaluator_counts, on=['姓名', '学号'], how='left')\n",
    "\n",
    "# 填充NaN为0\n",
    "result['被评总次数'] = result['被评总次数'].fillna(0)\n",
    "result['被评平均分'] = result['被评平均分'].fillna(0)\n",
    "result['评价他人海报总次数'] = result['评价他人海报总次数'].fillna(0)\n",
    "\n",
    "# 输出结果\n",
    "print(result[['海报序号', '姓名', '被评总次数', '被评平均分', '评价他人海报总次数']])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Auto-UI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
