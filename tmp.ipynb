{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available GPUs: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:2', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:3', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:4', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:5', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:6', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:7', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1,2,3,4,5,6,7\"\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "print(\"Available GPUs:\", gpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-29 15:43:54.146966: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-07-29 15:43:54.169917: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-07-29 15:43:54.176952: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-07-29 15:43:54.195712: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-29 15:43:55.260484: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR:tensorflow:Tensorflow needs to be built with TensorRT support enabled to allow TF-TRT to operate.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-29 15:43:56.813654: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2343] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2024-07-29 15:43:56.854187: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Tensorflow has not been built with TensorRT support.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 12\u001b[0m\n\u001b[1;32m      5\u001b[0m model \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mSequential([\n\u001b[1;32m      6\u001b[0m     tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mInput(shape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m784\u001b[39m,)),\n\u001b[1;32m      7\u001b[0m     tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mDense(\u001b[38;5;241m128\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[1;32m      8\u001b[0m     tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mDense(\u001b[38;5;241m10\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msoftmax\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      9\u001b[0m ])\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# 转换为 TensorRT 模型\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m converter \u001b[38;5;241m=\u001b[39m \u001b[43mtrt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTrtGraphConverterV2\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_saved_model_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpath_to_saved_model\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m converter\u001b[38;5;241m.\u001b[39mconvert()\n\u001b[1;32m     14\u001b[0m converter\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpath_to_saved_model_trt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/data/wxd/miniconda3/envs/Auto-UI/lib/python3.12/site-packages/tensorflow/python/util/deprecation.py:588\u001b[0m, in \u001b[0;36mdeprecated_args.<locals>.deprecated_wrapper.<locals>.new_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    580\u001b[0m         _PRINTED_WARNING[(func, arg_name)] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    581\u001b[0m       _log_deprecation(\n\u001b[1;32m    582\u001b[0m           \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFrom \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m: calling \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m (from \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m) with \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m is deprecated and will \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    583\u001b[0m           \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbe removed \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mInstructions for updating:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    586\u001b[0m           \u001b[38;5;124m'\u001b[39m\u001b[38;5;124min a future version\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m date \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m date),\n\u001b[1;32m    587\u001b[0m           instructions)\n\u001b[0;32m--> 588\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/data/wxd/miniconda3/envs/Auto-UI/lib/python3.12/site-packages/tensorflow/python/compiler/tensorrt/trt_convert.py:1261\u001b[0m, in \u001b[0;36mTrtGraphConverterV2.__init__\u001b[0;34m(self, input_saved_model_dir, input_saved_model_tags, input_saved_model_signature_key, use_dynamic_shape, dynamic_shape_profile_strategy, max_workspace_size_bytes, precision_mode, minimum_segment_size, maximum_cached_engines, use_calibration, allow_build_at_runtime, conversion_params)\u001b[0m\n\u001b[1;32m   1252\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m conversion_params \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1253\u001b[0m   conversion_params \u001b[38;5;241m=\u001b[39m TrtConversionParams(\n\u001b[1;32m   1254\u001b[0m       max_workspace_size_bytes\u001b[38;5;241m=\u001b[39mmax_workspace_size_bytes,\n\u001b[1;32m   1255\u001b[0m       precision_mode\u001b[38;5;241m=\u001b[39mprecision_mode,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1258\u001b[0m       use_calibration\u001b[38;5;241m=\u001b[39muse_calibration,\n\u001b[1;32m   1259\u001b[0m       allow_build_at_runtime\u001b[38;5;241m=\u001b[39mallow_build_at_runtime)\n\u001b[0;32m-> 1261\u001b[0m \u001b[43m_check_trt_version_compatibility\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1262\u001b[0m _check_conversion_params(conversion_params, is_v2\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   1264\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_conversion_params \u001b[38;5;241m=\u001b[39m conversion_params\n",
      "File \u001b[0;32m/data/wxd/miniconda3/envs/Auto-UI/lib/python3.12/site-packages/tensorflow/python/compiler/tensorrt/trt_convert.py:224\u001b[0m, in \u001b[0;36m_check_trt_version_compatibility\u001b[0;34m()\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _pywrap_py_utils\u001b[38;5;241m.\u001b[39mis_tensorrt_enabled():\n\u001b[1;32m    220\u001b[0m   logging\u001b[38;5;241m.\u001b[39merror(\n\u001b[1;32m    221\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTensorflow needs to be built with TensorRT support enabled to allow \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    222\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTF-TRT to operate.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 224\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTensorflow has not been built with TensorRT support.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    226\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m platform\u001b[38;5;241m.\u001b[39msystem() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWindows\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    227\u001b[0m   logging\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    228\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWindows support is provided experimentally. No guarantee is made \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    229\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mregarding functionality or engineering support. Use at your own risk.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Tensorflow has not been built with TensorRT support."
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.compiler.tensorrt import trt_convert as trt\n",
    "\n",
    "# 创建一个简单的模型\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(784,)),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# 转换为 TensorRT 模型\n",
    "converter = trt.TrtGraphConverterV2(input_saved_model_dir='path_to_saved_model')\n",
    "converter.convert()\n",
    "converter.save('path_to_saved_model_trt')\n",
    "\n",
    "# 加载 TensorRT 模型\n",
    "loaded_model = tf.saved_model.load('path_to_saved_model_trt')\n",
    "\n",
    "# 进行推理\n",
    "input_data = tf.random.uniform(shape=(1, 784))\n",
    "predictions = loaded_model(input_data)\n",
    "print(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorted Positions:\n",
      " [[ 10  30 150 250]\n",
      " [ 50  20 100 200]\n",
      " [ 70  25 120 220]]\n",
      "Sorted UI Text:\n",
      " ['Text B', 'Text A', 'Text C']\n",
      "Sorted UI Type:\n",
      " ['Type B', 'Type A', 'Type C']\n"
     ]
    }
   ],
   "source": [
    "import jax.numpy as jnp\n",
    "\n",
    "def sort_by_up_corner(positions, ui_text, ui_type):\n",
    "    # Extract the up_corner_pos from positions\n",
    "    up_corner_pos = positions[:, 0]  # Assuming up_corner_pos is the first element in each bounding box\n",
    "    \n",
    "    # Get the sorted indices based on up_corner_pos\n",
    "    sorted_indices = jnp.argsort(up_corner_pos)\n",
    "    \n",
    "    # Sort positions, ui_text, and ui_type based on sorted_indices\n",
    "    sorted_positions = positions[sorted_indices]\n",
    "    sorted_ui_text = [ui_text[i] for i in sorted_indices]\n",
    "    sorted_ui_type = [ui_type[i] for i in sorted_indices]\n",
    "    \n",
    "    return sorted_positions, sorted_ui_text, sorted_ui_type\n",
    "\n",
    "# Example usage\n",
    "positions = jnp.array([\n",
    "    [50, 20, 100, 200],\n",
    "    [10, 30, 150, 250],\n",
    "    [70, 25, 120, 220]\n",
    "])\n",
    "\n",
    "ex = {\n",
    "    'ui_text': ['Text A', 'Text B', 'Text C'],\n",
    "    'ui_type': ['Type A', 'Type B', 'Type C']\n",
    "}\n",
    "\n",
    "sorted_positions, sorted_ui_text, sorted_ui_type = sort_by_up_corner(positions, ex['ui_text'], ex['ui_type'])\n",
    "\n",
    "print(\"Sorted Positions:\\n\", sorted_positions)\n",
    "print(\"Sorted UI Text:\\n\", sorted_ui_text)\n",
    "print(\"Sorted UI Type:\\n\", sorted_ui_type)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Auto-UI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
